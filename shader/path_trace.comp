#version 460

#extension GL_GOOGLE_include_directive: require
#extension GL_EXT_ray_tracing : enable
#extension GL_EXT_ray_query : enable

#include "structs.glsl"

#define PI 3.1415926535897932384626433832
#define INV_PI 0.3183098861837906715377675267
#define EPS 0.1e-10
#define INV_GAMMA 0.454545454545

layout(local_size_x = 32, local_size_y = 32, local_size_z = 1) in;

layout(constant_id = 0) const uint TEXTURE_COUNT = 1;

layout(push_constant) uniform PushConstant {
    PathTracerPushConstants pc;
};

layout(binding = 0) uniform UniformBuffer
{
    CameraData camera_data;
};
layout(binding = 1) uniform accelerationStructureEXT topLevelAS;
layout(binding = 2, rgba8) uniform restrict readonly image2D input_image;
layout(binding = 3, rgba8) uniform restrict writeonly image2D output_image;
layout(binding = 4) readonly buffer InputPixelBuffer
{
    PixelData input_pixel_data[];
};
layout(binding = 5) writeonly buffer OutputPixelBuffer
{
    PixelData output_pixel_data[];
};
layout(binding = 10) readonly buffer VertexBuffer
{
    AlignedVertex vertices[];
};
layout(binding = 11) readonly buffer IndexBuffer
{
    uint indices[];
};
layout(binding = 12) readonly buffer MaterialBuffer
{
    Material materials[];
};
layout(binding = 13) readonly buffer MeshRenderDataBuffer
{
    MeshRenderData mesh_render_data[];
};
layout(binding = 14) readonly buffer ModelMRDIndicesBuffer
{
    uint model_mrd_indices[];
};
layout(binding = 15) uniform sampler2D tex_sampler[TEXTURE_COUNT];
layout(binding = 16) readonly buffer LightBuffer
{
    Light lights[];
};

#include "random.glsl"
#include "spectral.glsl"

bool evaluate_ray(in vec3 ro, in vec3 rd, out float t, out int instance_id, out int geometry_idx, out int primitive_idx, out vec2 bary)
{
    rayQueryEXT rayQuery;
    rayQueryInitializeEXT(rayQuery, topLevelAS, gl_RayFlagsNoneEXT, 0xFF, ro, 0.001, rd, 10000.0);
    rayQueryProceedEXT(rayQuery);
    if (rayQueryGetIntersectionTypeEXT(rayQuery, true) == gl_RayQueryCommittedIntersectionTriangleEXT)
    {
        t = rayQueryGetIntersectionTEXT(rayQuery, true);
        instance_id = rayQueryGetIntersectionInstanceCustomIndexEXT(rayQuery, true);
        geometry_idx = rayQueryGetIntersectionGeometryIndexEXT(rayQuery, true);
        primitive_idx = rayQueryGetIntersectionPrimitiveIndexEXT(rayQuery, true);
        bary = rayQueryGetIntersectionBarycentricsEXT(rayQuery, true);
        return true;
    }
    return false;
}

vec2 concentric_sample_disk() {
    vec2 u = vec2(pcg_random_state(), pcg_random_state());
    vec2 u_offset = 2.0f * u - vec2(1, 1);
    if (u_offset.x == 0 && u_offset.y == 0)
        return vec2(0, 0);
    float theta, r;
    if (abs(u_offset.x) > abs(u_offset.y))
    {
        r = u_offset.x;
        theta = PI / 4 * (u_offset.y / u_offset.x);
    }
    else
    {
        r = u_offset.y;
        theta = PI / 2 - PI / 4 * (u_offset.x / u_offset.y);
    }
    return r * vec2(cos(theta), sin(theta));
}

vec3 cosine_sample_hemisphere(in vec3 n) {
    vec2 d = concentric_sample_disk();
    float z = sqrt(max(0, 1 - d.x * d.x - d.y * d.y));
    vec3 v2, v3;
    if (abs(n.x) > abs(n.y))
    {
        v2 = vec3(-n.z, 0, n.x) / sqrt(n.x * n.x + n.z * n.z);
    }
    else
    {
        v2 = vec3(0, n.z, -n.y) / sqrt(n.y * n.y + n.z * n.z);
    }
    v3 = cross(n, v2);
    vec3 w = z * n - d.x * v3 - d.y * v2;;
    return w;
}

vec3 importance_sample_ggx(in vec3 n, in float roughness)
{
    float r2 = roughness * roughness;
    vec2 xi = vec2(pcg_random_state(), pcg_random_state());
    float phi = 2.0 * PI * xi.x;
    float cos_theta = sqrt((1.0 - xi.y) / (1.0 + (r2 - 1.0) * xi.y));
    float sin_theta = sqrt(1.0 - cos_theta * cos_theta);

    // spherical coordinates to cartesian coordinates
    vec3 h;
    h.x = cos(phi) * sin_theta;
    h.y = sin(phi) * sin_theta;
    h.z = cos_theta;

    // tangent-space vector to world-space sample vector
    vec3 up = abs(n.z) < 0.999 ? vec3(0.0, 0.0, 1.0) : vec3(1.0, 0.0, 0.0);
    vec3 tangent = normalize(cross(up, n));
    vec3 bitangent = cross(n, tangent);

    return normalize(h.z * n - tangent * h.x + bitangent * h.y);
}

float brdf_oren_nayar(in vec3 l, in vec3 n, in vec3 v, float r)
{
    float r2 = r * r;
    float a = 1.0 - (r2 / (2.0 * r2 + 0.33));
    float b = ((0.45 * r2) / (r2 + 0.09));
    float nl = dot(l, n);
    float nv = dot(v, n);
    float ga = dot(normalize(v - n * nv), normalize(l - n * nl));
    float theta_i = acos(nv);
    float theta_o = acos(nl);
    return INV_PI * (a + b * max(ga, 0.0) * sin(max(theta_i, theta_o)) * tan(min(theta_i, theta_o)));
}

float ndf_ggx(in float nh, in float r)
{
    float r2 = r * r;
    float denom = (nh * nh * (r2 - 1.0) + 1.0);
    denom = PI * denom * denom;
    return r2 / max(denom, EPS);
}

float geometry_schlick_ggx(in float nl, in float nv, in float r)
{
    float r2 = r * r;
    float gv = nv / (nv * (1 - r2) + r2);
    float gl = nl / (nl * (1 - r2) + r2);
    return max(gv * gl, EPS);
}

vec3 fresnel_schlick(in float vh, in vec3 F0)
{
    return F0 + (1.0 - F0) * pow(1.0 - vh, 5.0);
}

vec4 brdf_cook_torrance(in vec3 h, in vec3 l, in vec3 n, in vec3 v, in vec3 albedo, in float metallic, in float r)
{
    vec3 F0 = vec3(0.04); 
    F0 = mix(F0, albedo, metallic);
    float nh = clamp(dot(n, h), 0.0, 1.0);
    float nv = clamp(dot(n, v), 0.0, 1.0);
    float nl = clamp(dot(n, l), 0.0, 1.0);
    float vh = clamp(dot(v, h), 0.0, 1.0);

    // float D = ndf_ggx(nh, r);
    float G = geometry_schlick_ggx(nl, nv, r);
    vec3 F = fresnel_schlick(vh, F0);
    // Microfacet specular = D * G * F / (4 * nl * nv)
    // pdf = D * nh / (4 * vh)
    // solid angle cosine = nl
    vec3 specular = nl > 0 ? (F * G * vh) / max((nh * nv), EPS) : vec3(0.0);
    return vec4((1 - metallic) * (brdf_oren_nayar(l, n, v, r) * albedo + F) + (metallic) * specular, 1.0);
}

void apply_surface_parameters(in MeshRenderData mrd, in Vertex vertex, in vec3 v, inout vec4 emission, inout vec4 attenuation, out vec3 l)
{
    l = cosine_sample_hemisphere(vertex.normal);
    // object does not have material, make it fully diffuse with the vertex color
    if (mrd.mat_idx < 0)
    {
        attenuation *= brdf_oren_nayar(l, vertex.normal, v, 1.0) * vertex.color;
        return;
    }
    Material m = materials[mrd.mat_idx];
    // add attenuated emission of material
    if (length(m.emission) > 0.0) emission += attenuation * m.emission * m.emission_strength;
    // get color of material at position
    vec4 color = vec4(0.0);
    if (m.base_texture >= 0) color = texture(tex_sampler[m.base_texture], vertex.tex);
    else if (length(m.base_color) > 0.0) color = m.base_color;
    else color = vec4(0.0, 0.0, 0.0, 0.0);
    vec3 h = normalize(v + l);
    // only full metallic or non metallic is possible as otherwise the importance sampling probabilities are incorrect
    if (m.metallic == 1.0)
    {
        h = importance_sample_ggx(vertex.normal, m.roughness);
        l = normalize(2 * dot(v, h) * h - v);
        attenuation *= brdf_cook_torrance(h, l, vertex.normal, v, color.rgb, m.metallic, m.roughness);
    }
    else
    {
        attenuation *= brdf_oren_nayar(l, vertex.normal, v, m.roughness) * color;
    }
}

Vertex interpolate_attributes(in MeshRenderData mrd, in int primitive_idx, in vec2 bary)
{
    Vertex v0 = unpack_vertex(vertices[indices[mrd.indices_idx + primitive_idx * 3]]);
    Vertex v1 = unpack_vertex(vertices[indices[mrd.indices_idx + primitive_idx * 3 + 1]]);
    Vertex v2 = unpack_vertex(vertices[indices[mrd.indices_idx + primitive_idx * 3 + 2]]);
    Vertex v;
    v.normal = normalize((1.0 - bary.x - bary.y) * v0.normal + bary.x * v1.normal + bary.y * v2.normal);
    v.color = (1.0 - bary.x - bary.y) * v0.color + bary.x * v1.color + bary.y * v2.color;
    v.tex = (1.0 - bary.x - bary.y) * v0.tex + bary.x * v1.tex + bary.y * v2.tex;
    return v;
}

#define PATH_LENGTH 8

void main()
{
    ivec2 viewport_size = imageSize(output_image);
    ivec2 pixel = ivec2(gl_GlobalInvocationID.xy);
    if (pixel.x > viewport_size.x || pixel.y > viewport_size.y) return;
    rng_state = (pixel.y * viewport_size.x + pixel.x + (pc.sample_count + 3) * viewport_size.x * viewport_size.y);
    vec2 jitter = vec2(pcg_random_state(), pcg_random_state()) - 0.5;
    vec2 norm_pixel = ((vec2(pixel) + jitter) / vec2(viewport_size) - 0.5) * camera_data.sensor_size;
    vec3 p = camera_data.pos;
    vec3 dir = normalize(-camera_data.w * camera_data.focal_length + norm_pixel.x * camera_data.u + norm_pixel.y * camera_data.v);
    vec4 out_color = vec4(0.0, 0.0, 0.0, 0.0);
    vec4 emission = vec4(0.0, 0.0, 0.0, 0.0);
    vec4 attenuation = vec4(1.0, 1.0, 1.0, 1.0);
    uint wavelength = get_random_wavelength(pcg_random_state());
    float t = 0.0;
    int instance_id = 0;
    int primitive_idx = 0;
    int geometry_idx = 0;
    vec2 bary = vec2(0.0);
    Vertex vertex;
    MeshRenderData mrd;
    for (uint i = 0; i < PATH_LENGTH; ++i)
    {
        if (evaluate_ray(p, dir, t, instance_id, geometry_idx, primitive_idx, bary))
        {
            mrd = mesh_render_data[model_mrd_indices[instance_id] + geometry_idx];
            vertex = interpolate_attributes(mrd, primitive_idx, bary);
            vec3 v = -dir;
            p = p + dir * t;
            apply_surface_parameters(mrd, vertex, v, emission, attenuation, dir);
            if (pc.attenuation_view || pc.emission_view || pc.normal_view || pc.tex_view) break;
        }
        else
        {
            attenuation = vec4(0.0);
            vertex.normal = vec3(0.0);
            vertex.tex = vec2(0.0);
            break;
        }
    }
    if (pc.attenuation_view) out_color = attenuation;
    else if (pc.emission_view) out_color = emission;
    else if (pc.normal_view) out_color = vec4((vertex.normal + 1.0) / 2.0, 1.0);
    else if (pc.tex_view) out_color = vec4(vertex.tex, 1.0, 1.0);
    else
    {
        // out_color is attenuated accumulated emission multiplied with spectral rgb response divided by probability of spectral sample
        out_color = emission * wavelength_to_rgba(wavelength) * get_inv_wavelength_probability();
        if (pc.sample_count > 0)
        {
            // interpolate with previous samples
            out_color = input_pixel_data[pixel.y * viewport_size.x + pixel.x].col * float(pc.sample_count - 1) / float(pc.sample_count) + out_color / float(pc.sample_count);
        }
    }
    output_pixel_data[pixel.y * viewport_size.x + pixel.x].col = out_color;
    imageStore(output_image, ivec2(pixel.x, viewport_size.y - pixel.y), pow(out_color, vec4(INV_GAMMA)));
}
